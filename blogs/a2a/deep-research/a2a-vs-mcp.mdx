---
title: "Model Context Protocol vs Google's A2A Protocol"
description: "Deep Research using ChatGPT o1-pro, by Rahul Parundekar. Published on 20th April, 2025."
icon: sparkles
---

| **Aspect** | **Model Context Protocol (MCP)** | **Google Agent-to-Agent (A2A) Protocol** |
| --- | --- | --- |
| **Design Focus & Architecture** | **Tool/Context Integration:** An open standard for “plug-in” style connections between LLMs and external data, tools, or APIs ([Mastering AI Interoperability: Google A2A vs. Anthropic MCP — Which to Use and When](https://blog.searce.com/mastering-ai-interoperability-google-a2a-vs-anthropic-mcp-which-to-use-and-when-af59e46cafef#:~:text=Anthropic%E2%80%99s%20MCP%2C%20introduced%20in%20November,regardless%20of%20the%20model%E2%80%99s%20provider)). Built on JSON-RPC 2.0 with stateful sessions and bi-directional requests ([Specification - Model Context Protocol](https://modelcontextprotocol.io/specification/2025-03-26#:~:text=The%20protocol%20uses%20JSON,messages%20to%20establish%20communication%20between)), inspired by the Language Server Protocol to standardize how AI systems get additional context and functions ([Specification - Model Context Protocol](https://modelcontextprotocol.io/specification/2025-03-26#:~:text=MCP%20takes%20some%20inspiration%20from,additional%20context%20and%20tools%20into)). Defines first-class entities like **Resources** (data context), **Tools** (callable functions), and **Prompts** (predefined templates) that a server can offer to a client ([Specification - Model Context Protocol](https://modelcontextprotocol.io/specification/2025-03-26#:~:text=Servers%20offer%20any%20of%20the,following%20features%20to%20clients)). The design is modular – every MCP implementation supports core JSON-RPC messaging and capability negotiation, and can optionally support extra features as needed. This layered approach keeps the protocol lean while allowing rich extensions (e.g. logging, streaming, auth) without breaking core compatibility. | **Agent Collaboration:** An open protocol for multi-agent interoperability across different frameworks or vendors ([A2A/README.md at main · google/A2A · GitHub](https://github.com/google/A2A/blob/main/README.md#:~:text=One%20of%20the%20biggest%20challenges,%E2%80%93%20all%20while)). Centers on HTTP-based JSON messaging: agents expose a RESTful endpoint (often at `/.well-known/agent.json`) with an **Agent Card** describing their capabilities and skills for discovery ([A2A/README.md at main · google/A2A · GitHub](https://github.com/google/A2A/blob/main/README.md#:~:text=,to%20an%20A2A%20Server%27s%20URL)). Interactions are framed as **Tasks**: a client agent sends a `tasks/send` request to a peer’s endpoint to initiate a dialog or command, optionally maintaining a session ID for multi-turn exchanges ([a2a-directory/docs/a2a-sample-methods-and-json-responses.md at main · sing1ee/a2a-directory · GitHub](https://github.com/sing1ee/a2a-directory/blob/main/docs/a2a-sample-methods-and-json-responses.md#:~:text=%7B%20,)). Communication is asynchronous and long-lived: A2A uses Server-Sent Events (SSE) or webhooks for streaming updates and push notifications on task progress ([A2A/README.md at main · google/A2A · GitHub](https://github.com/google/A2A/blob/main/README.md#:~:text=,tasks%2FpushNotification%2Fset)). Messages in a task have roles (`"user"` or `"agent"`) and are composed of **Parts** (text, file, or structured data), enabling richer modalities than plain text ([A2A/README.md at main · google/A2A · GitHub](https://github.com/google/A2A/blob/main/README.md#:~:text=,forms)). The protocol emphasizes capability negotiation – agents advertise supported interaction modes (text, forms, audio) and authentication requirements in their Agent Card – so that two agents can agree on how to converse or cooperate securely. |
| **Developer Experience (Integration, Extensibility, Tooling)** | **Mature & Integrator-Friendly:** MCP comes with official SDKs in multiple languages (Python, TypeScript, Java, Kotlin, C#) ([Overview - Model Context Protocol](https://modelcontextprotocol.io/specification/2025-03-26/basic#:~:text=,Kotlin%20SDK)), making it easy to integrate. For example, the Python SDK lets developers decorate functions as tools or expose data resources; the library handles all JSON-RPC plumbing behind the scenes ([GitHub - modelcontextprotocol/python-sdk: The official Python SDK for Model Context Protocol servers and clients](https://github.com/modelcontextprotocol/python-sdk#:~:text=,return%20a%20%2B%20b)) ([GitHub - modelcontextprotocol/python-sdk: The official Python SDK for Model Context Protocol servers and clients](https://github.com/modelcontextprotocol/python-sdk#:~:text=The%20Model%20Context%20Protocol%20,MCP%20servers%20can)). This model feels familiar – “like a web API for LLMs” – so existing API/service patterns apply ([GitHub - modelcontextprotocol/python-sdk: The official Python SDK for Model Context Protocol servers and clients](https://github.com/modelcontextprotocol/python-sdk#:~:text=The%20Model%20Context%20Protocol%20,MCP%20servers%20can)). MCP’s schema-driven design (the spec is based on a TypeScript schema) and capability negotiation make it **extensible**: developers can start simple (implement just the needed tool or resource methods) and later enable optional features (streaming, cancellation, etc.) without changes to the core protocol. Recent updates even added HTTP & SSE transport support for more deployment flexibility (beyond persistent sockets) and OAuth2-based auth, showing responsiveness to developer needs ([The Creators of Model Context Protocol - Latent.Space](https://www.latent.space/p/mcp#:~:text=And%20since%20then%2C%20we%E2%80%99ve%20added,1)). Tool builders benefit from **write-once, use-anywhere**: an MCP-compatible tool server can work with any MCP-aware AI client (Anthropic, OpenAI, etc.), fostering an ecosystem of reusable tools ([MCP Simply Explained: Function Calling Rebranded or Genuine ...](https://dev.to/zachary62/model-context-protocol-mcp-simply-explained-function-calling-rebranded-or-genuine-breakthrough-4c04#:~:text=%E2%9C%93%20For%20Tool%20Builders%3A%20MCP,system%20without%20modifying%20source%20code)). The community and big players are rallying around MCP (it’s being adopted in AI platforms and IDEs), so plenty of tooling has emerged – CLI inspectors, debugging UIs, and a growing “hub” of MCP servers – which further improves DX. | **Emerging but Promising:** Backed by Google, A2A is open-sourced and inviting community contributions ([A2A/README.md at main · google/A2A · GitHub](https://github.com/google/A2A/blob/main/README.md#:~:text=match%20at%20L350%20A2A%20Protocol,contributions%20from%20the%20entire%20community)), but it’s newer and evolving. Developers currently rely on provided examples and libraries: Google offers reference implementations (clients/servers in Python and JS) that wrap the HTTP + SSE mechanics (e.g. a Python `A2AClient` class handles HTTP requests and event streams for you) ([What is The Agent2Agent Protocol (A2A) and Why You Must Learn It Now](https://huggingface.co/blog/lynn-mikami/agent2agent#:~:text=Any%20application%20or%20another%20agent,the%20responses%20or%20streamed%20events)). Integration entails running a web service endpoint for your agent – straightforward for cloud services, slightly more overhead for local agents (the samples use lightweight frameworks like Starlette/FastAPI to spin up an A2A endpoint ([What is The Agent2Agent Protocol (A2A) and Why You Must Learn It Now](https://huggingface.co/blog/lynn-mikami/agent2agent#:~:text=responses%20or%20streams%20updates))). The upside is that A2A aligns with web standards (JSON payloads, RESTful patterns, OAuth support) ([Mastering AI Interoperability: Google A2A vs. Anthropic MCP — Which to Use and When](https://blog.searce.com/mastering-ai-interoperability-google-a2a-vs-anthropic-mcp-which-to-use-and-when-af59e46cafef#:~:text=,sharing%20updates%20in%20real%20time)), so existing enterprise infrastructure (load balancers, auth mechanisms) and tools (API gateways, Postman) can slot in easily. **Extensibility** is considered in design: the Agent Card format can be extended with new fields (and future plans include methods like `QuerySkill()` for dynamic capability queries) ([A2A/README.md at main · google/A2A · GitHub](https://github.com/google/A2A/blob/main/README.md#:~:text=,conversation)). Early adopters have created adaptors for popular agent frameworks (e.g. LangChain, Semantic Kernel) ([A2A/README.md at main · google/A2A · GitHub](https://github.com/google/A2A/blob/main/README.md#:~:text=%2A%20Multi,78)), indicating growing ecosystem support. However, since A2A is in an “early development stage” ([a2a-directory/docs/a2a-vs-mcp.md at main · sing1ee/a2a-directory · GitHub](https://github.com/sing1ee/a2a-directory/blob/main/docs/a2a-vs-mcp.md#:~:text=Abstraction%20Level%20Low,standardizing%20In%20early%20development%20stage)), developers may encounter rough edges (e.g. managing task state and authentication across systems) – areas the project is actively improving with community feedback. |
| **Common Interaction Example** | **Tool Invocation:** MCP uses JSON-RPC requests for function calls. For example, to call a tool named **`write_note`** exposed by an MCP server, a client sends a request like:<br/>`{`<br/>`  "method": "tools/call",`<br/>`  "params": { "name": "write_note", "arguments": { "slug": "morning", "content": "Start your day with clarity." } },`<br/>`  "id": 2`<br/>`}` ([What are MCP Tools?](https://www.speakeasy.com/mcp/tools#:~:text=)). <br/>The MCP server will execute the corresponding function and return the result in a JSON-RPC response (or an error, using JSON-RPC’s standard error format) ([What are MCP Tools?](https://www.speakeasy.com/mcp/tools#:~:text=)). In code, using the SDK, this pattern is abstracted – e.g. a Python developer simply defines `@mcp.tool()` functions, and the MCP library handles incoming `tools/call` messages and returns outputs automatically. | **Agent Messaging Task:** In A2A, one agent creates a **Task** to engage another. For example, a client agent might send a JSON request to a peer’s A2A endpoint to start a task:<br/>`{`<br/>`  "jsonrpc": "2.0", "id": 1,`<br/>`  "method": "tasks/send",`<br/>`  "params": { "id": "123e4567- task-uuid -890",`<br/>`    "message": { "role": "user", "parts": [ { "type": "text", "text": "Tell me a joke." } ] } }`<br/>`}` ([a2a-directory/docs/a2a-sample-methods-and-json-responses.md at main · sing1ee/a2a-directory · GitHub](https://github.com/sing1ee/a2a-directory/blob/main/docs/a2a-sample-methods-and-json-responses.md#:~:text=%7B%20,)).<br/>The remote agent (acting as an A2A server) processes this task. It may respond immediately with a final answer, or (if using streaming) send incremental updates/events as the task goes through states. The eventual result is delivered as a Task object containing any output artifacts – for example, a completed task might return an artifact with a text part: “Why did the chicken cross the road? …” ([a2a-directory/docs/a2a-sample-methods-and-json-responses.md at main · sing1ee/a2a-directory · GitHub](https://github.com/sing1ee/a2a-directory/blob/main/docs/a2a-sample-methods-and-json-responses.md#:~:text=%7B%20,%7D)). Clients can then continue the conversation by sending another `tasks/send` with the same task ID (if the agent asks for more input), or retrieve the task history/status via `tasks/get`. This request/response pattern, combined with streaming, allows agents to have back-and-forth dialogues or delegations in a structured way. |
| **Use-Case Fit: LLM Agent ↔ Tool** | **⭐ Strengths:** MCP is **purpose-built for agent-to-tool** linking. It treats tools and data sources as first-class citizens, making it straightforward for an LLM-based agent to call functions or query data in a controlled, structured manner. Think of MCP as the “**USB-C port**” that standardizes how an AI model plugs into external functions and data ([Agent to agent, not tool to tool: an engineer’s guide to Google’s A2A protocol — WorkOS](https://workos.com/blog/engineers-guide-to-googles-a2a-protocol#:~:text=Anthropic%E2%80%99s%20Model%20Context%20Protocol%20,database%20rows%2C%20or%20API%20handles)). This yields a consistent developer experience for tool integration across different models (Claude, GPT, etc.) ([Mastering AI Interoperability: Google A2A vs. Anthropic MCP — Which to Use and When](https://blog.searce.com/mastering-ai-interoperability-google-a2a-vs-anthropic-mcp-which-to-use-and-when-af59e46cafef#:~:text=,to%20generate%20accurate%20Python%20code)). Moreover, MCP’s request/response style and explicit schemas ensure that tool outputs can be reliably fed back into the model. **Security** is addressed through its permission and consent guidelines (e.g. requiring user approval for any tool execution) ([Specification - Model Context Protocol](https://modelcontextprotocol.io/specification/2025-03-26#:~:text=,LLM%20Sampling%20Controls)) ([Specification - Model Context Protocol](https://modelcontextprotocol.io/specification/2025-03-26#:~:text=,LLM%20Sampling%20Controls)), which is vital when connecting powerful tools. <br/>**⚠️ Weaknesses:** Being request/reply oriented, MCP by itself doesn’t handle complex multi-step tool use without additional orchestration – the agent (LLM) is expected to decide when to call `tools/call` and handle the results. Also, integrating a simple REST API via MCP adds an extra layer; for one-off integrations, some developers might find it simpler to call the API directly. (MCP’s value shows when you want a **standard** interface so the same agent can work with many tools interchangeably.) Initially, MCP assumed a persistent connection environment (like an IDE plugin) which made web integration trickier, but the latest spec added stateless HTTP support to mitigate this ([The Creators of Model Context Protocol - Latent.Space](https://www.latent.space/p/mcp#:~:text=And%20since%20then%2C%20we%E2%80%99ve%20added,1)). Overall, for empowering a single LLM with an extendable toolbox of skills and data access, MCP is highly effective and widely regarded as the go-to standard. | **⭐ Strengths:** A2A’s focus is elsewhere (multi-agent), so it doesn’t natively shine in a solo agent→tool scenario. In practice, one could wrap a tool as a trivial “agent” exposing one skill, allowing other agents to call it via A2A – but this is essentially treating the tool like a full agent service. A2A does not provide function-call semantics out of the box; everything is an agent message. Thus its main strength here would be if the “tool” itself is complex enough to warrant an agent interface (for example, a standalone AI service that might internally use tools). A2A can then facilitate a standardized conversation with that service. It also inherits web-friendly security features (auth tokens, etc.), so an enterprise might expose certain internal tools as A2A agents with proper authentication – leveraging the protocol’s task management and auditability. <br/>**⚠️ Weaknesses:** For straightforward tool use (like calling a calculator or database), A2A is **overkill**. It requires standing up an HTTP endpoint and conforming to the task lifecycle for what might otherwise be a simple function call. There’s more overhead (JSON messages, task IDs, state management) compared to MCP’s direct RPC call. Moreover, A2A lacks the fine-grained function schema concept; an A2A “skill” is described in the Agent Card, but invoking it is still done via a generic `tasks/send` message rather than a typed function call ([a2a-directory/docs/a2a-vs-mcp.md at main · sing1ee/a2a-directory · GitHub](https://github.com/sing1ee/a2a-directory/blob/main/docs/a2a-vs-mcp.md#:~:text=MCP%20,like%20how%20programmers%20call%20functions)). In short, A2A wasn’t designed for the model-to-tool use-case – it *can* be bent to that purpose, but doing so sacrifices the simplicity that MCP offers. Most engineering teams choose MCP or built-in model plugins for tool integration, and reserve A2A for what it truly excels at (agent-to-agent coordination) ([Agent to agent, not tool to tool: an engineer’s guide to Google’s A2A protocol — WorkOS](https://workos.com/blog/engineers-guide-to-googles-a2a-protocol#:~:text=Think%20of%20MCP%20as%20%E2%80%9Cplug,%E2%80%9D)) ([Mastering AI Interoperability: Google A2A vs. Anthropic MCP — Which to Use and When](https://blog.searce.com/mastering-ai-interoperability-google-a2a-vs-anthropic-mcp-which-to-use-and-when-af59e46cafef#:~:text=While%20both%20A2A%20and%20MCP,comparison%20to%20clarify%20their%20strengths)). |
| **Use-Case Fit: Agent ↔ Agent** | **⭐ Strengths:** MCP enables a form of agent-tool chaining, but it does **not** natively handle two autonomous agents talking to each other as peers. You would typically need a custom coordinator: e.g. one agent treats the other as an MCP server exposing some tools or data. This means one agent is in control and the other is essentially a resource provider, which isn’t a true symmetric “conversation.” There’s no standard MCP mechanism for agent discovery or mutual negotiation of dialog format – you’d have to configure connections manually. That said, an agent could use MCP to query another agent’s data or trigger an action if you set it up that way, but the lack of multi-turn task context and cross-agent protocol means it’s clunky for back-and-forth communication. Even the creators of MCP acknowledge that when you “want multiple autonomous agents…you hit a new wall” that MCP alone doesn’t solve ([Agent to agent, not tool to tool: an engineer’s guide to Google’s A2A protocol — WorkOS](https://workos.com/blog/engineers-guide-to-googles-a2a-protocol#:~:text=LLM%20is%20given%20files%2C%20database,rows%2C%20or%20API%20handles)). **Security and trust** also become trickier in a DIY multi-agent setup, since MCP wasn’t built with chaining many agents in mind (it focuses on a trusted host-server pair with user in the loop). In sum, MCP by itself is not ideal for agent-to-agent collaboration – it’s complementary to A2A, not a replacement ([a2a-directory/docs/a2a-vs-mcp.md at main · sing1ee/a2a-directory · GitHub](https://github.com/sing1ee/a2a-directory/blob/main/docs/a2a-vs-mcp.md#:~:text=A2A%20and%20MCP%20are%20not,need%20to%20be%20used%20together)). <br/>**⚠️ Weaknesses:** (See above – the weaknesses for multi-agent use are essentially the flip side of its design strengths for single-agent tool use. The structured, tightly scoped nature of MCP doesn’t easily accommodate the open-ended nature of agent dialogues.) | **⭐ Strengths:** A2A was explicitly designed for **agent-to-agent communication**, and this is where it excels. It provides a common language for agents to **discover each other, declare capabilities, and coordinate tasks** securely ([A2A/README.md at main · google/A2A · GitHub](https://github.com/google/A2A/blob/main/README.md#:~:text=One%20of%20the%20biggest%20challenges,%E2%80%93%20all%20while)). The built-in task lifecycle (with states like “working” or “input-required”) is extremely useful when agents collaborate on long-running or multi-step goals – one agent can pause and ask the other for input, then resume, all tracked within the protocol. A2A’s message format (role-based turns with rich content parts) allows agents to have nuanced dialogues or exchange data (e.g. one agent can send a file or a structured JSON to another as part of a task). Crucially, A2A formalizes **discovery**: via the Agent Card, an agent can programmatically find out what another agent can do (skills, modalities) and what auth is needed ([A2A/README.md at main · google/A2A · GitHub](https://github.com/google/A2A/blob/main/README.md#:~:text=,a%20task%20by%20sending%20a)). This is vital in a heterogeneous environment where agents might be running on different platforms – A2A gives a standardized handshake. It also supports **secure collaboration** out-of-the-box – for instance, an agent can require OAuth tokens or API keys as per its Agent Card, and the calling agent knows how to provide credentials, making cross-organization agent teamwork more feasible ([Mastering AI Interoperability: Google A2A vs. Anthropic MCP — Which to Use and When](https://blog.searce.com/mastering-ai-interoperability-google-a2a-vs-anthropic-mcp-which-to-use-and-when-af59e46cafef#:~:text=,sharing%20updates%20in%20real%20time)). <br/>**⚠️ Weaknesses:** Being new, A2A is still maturing; practical interoperability issues (like ensuring two agents maintain a consistent shared context or handling partial failures in a chain of agents) are areas of active development. There is also some performance and complexity overhead: two agents communicating via A2A incur HTTP call latency and need logic to manage task IDs and possibly reconnections for streaming. Engineering teams must also implement robust **state management** on the client side (to track multiple concurrent tasks and agent interactions), which is non-trivial ([a2a-directory/docs/a2a-vs-mcp.md at main · sing1ee/a2a-directory · GitHub](https://github.com/sing1ee/a2a-directory/blob/main/docs/a2a-vs-mcp.md#:~:text=A2A%20Challenges)). Finally, as with any multi-party system, security is complex – one must carefully configure trust, since giving an agent access to another agent’s endpoint is powerful. These challenges notwithstanding, for scenarios like distributed AI services, agent delegations, or agent “societies” working together on a problem, A2A’s design offers a strong foundation that simply didn’t exist before. It is generally considered the better choice over MCP when each entity in the interaction is an autonomous agent rather than a passive tool ([Mastering AI Interoperability: Google A2A vs. Anthropic MCP — Which to Use and When](https://blog.searce.com/mastering-ai-interoperability-google-a2a-vs-anthropic-mcp-which-to-use-and-when-af59e46cafef#:~:text=While%20both%20A2A%20and%20MCP,comparison%20to%20clarify%20their%20strengths)) ([Agent to agent, not tool to tool: an engineer’s guide to Google’s A2A protocol — WorkOS](https://workos.com/blog/engineers-guide-to-googles-a2a-protocol#:~:text=But%20as%20soon%20as%20you,tasks%20back%20and%20forth%20securely)). |

### Get Connected, Share, and Other Socials

<CardGroup>
  <Card 
    title="Share on LinkedIn" 
    description="Share this article on LinkedIn." 
    href="http://www.linkedin.com/shareArticle?mini=true&url=https://blog.elevate.do/a2a/deep-research/a2a" 
  />
  <Card 
    title="Share on X/Twitter" 
    description="Tweet this article to your followers." 
    href="https://twitter.com/intent/tweet?url=https://blog.elevate.do/a2a/deep-research/a2a" 
  />
  <Card 
    title="Have thoughts? I'd love to chat!" 
    description="Schedule a conversation with me." 
    href="https://calendar.app.google/a5e29gFgjHRiKaPV9" 
  />
  <Card 
		title="More about Rahul and Elevate.do" 
		description="More about Rahul, Elevate Human Experiences, LLC, and services offered" 
		href="https://elevate.do" 
	/>
	<Card
		title="Follow Rahul on LinkedIn" 
		description="Connect with or Follow Rahul Parundekar on LinkedIn." 
		href="https://www.linkedin.com/in/rparundekar/"
	/>
	<Card
		title="Follow Rahul on Twitter/X" 
		description="Follow Rahul Parundekar on Twitter/X." 
		href="https://x.com/RahulParundekar"
	/>
</CardGroup>
---
**Sources:** Official MCP Spec (2025-03-26) ([Specification - Model Context Protocol](https://modelcontextprotocol.io/specification/2025-03-26#:~:text=The%20protocol%20uses%20JSON,messages%20to%20establish%20communication%20between)) ([Specification - Model Context Protocol](https://modelcontextprotocol.io/specification/2025-03-26#:~:text=Servers%20offer%20any%20of%20the,following%20features%20to%20clients)); MCP Python SDK docs ([GitHub - modelcontextprotocol/python-sdk: The official Python SDK for Model Context Protocol servers and clients](https://github.com/modelcontextprotocol/python-sdk#:~:text=,return%20a%20%2B%20b)) ([GitHub - modelcontextprotocol/python-sdk: The official Python SDK for Model Context Protocol servers and clients](https://github.com/modelcontextprotocol/python-sdk#:~:text=The%20Model%20Context%20Protocol%20,MCP%20servers%20can)); Google A2A README and spec ([A2A/README.md at main · google/A2A · GitHub](https://github.com/google/A2A/blob/main/README.md#:~:text=,a%20task%20by%20sending%20a)) ([A2A/README.md at main · google/A2A · GitHub](https://github.com/google/A2A/blob/main/README.md#:~:text=,g)); WorkOS & Searce engineering blog analyses ([Agent to agent, not tool to tool: an engineer’s guide to Google’s A2A protocol — WorkOS](https://workos.com/blog/engineers-guide-to-googles-a2a-protocol#:~:text=Anthropic%E2%80%99s%20Model%20Context%20Protocol%20,database%20rows%2C%20or%20API%20handles)) ([Mastering AI Interoperability: Google A2A vs. Anthropic MCP — Which to Use and When](https://blog.searce.com/mastering-ai-interoperability-google-a2a-vs-anthropic-mcp-which-to-use-and-when-af59e46cafef#:~:text=While%20both%20A2A%20and%20MCP,comparison%20to%20clarify%20their%20strengths)); A2A sample JSON schema ([a2a-directory/docs/a2a-sample-methods-and-json-responses.md at main · sing1ee/a2a-directory · GitHub](https://github.com/sing1ee/a2a-directory/blob/main/docs/a2a-sample-methods-and-json-responses.md#:~:text=%7B%20,)); Speakeasy MCP tool guide ([What are MCP Tools?](https://www.speakeasy.com/mcp/tools#:~:text=)).